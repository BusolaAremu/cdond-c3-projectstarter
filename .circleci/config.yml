version: 2.1
orbs: 
  slack: circleci/slack@4.10.1

defaults: &dockerImage
  docker:
    - image: circleci/node:13.8.0



jobs:
  build-frontend:
    <<: *dockerImage
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Build front-end
          command: |
            cd frontend
            npm install
            npm run build
      - save_cache:
          paths: [frontend/node_modules]
          key: frontend-build
      - slack/notify:
          channel: 03-cloud-devops
          event: fail
          template: basic_fail_1

  build-backend:
    <<: *dockerImage
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build]
      - run:
          name: Back-end build
          command: |
            cd backend
            npm install
            npm run build
      - save_cache:
          paths: [backend/node_modules]
          key: backend-build
      - slack/notify:
          channel: 03-cloud-devops
          event: fail
          template: basic_fail_1

  test-frontend:
    <<: *dockerImage
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-test]
      - run:
          name: front-end test
          command: |
            cd frontend
            npm install
            npm run test
      - slack/notify:
          channel: 03-cloud-devops
          event: fail
          template: basic_fail_1

  test-backend:
    <<: *dockerImage
    steps:
      - checkout
      - restore_cache:
          keys: [backend-test]
      - run:
          name: back-end test
          command: |
            cd backend
            npm install
            npm run test
      - slack/notify:
          channel: 03-cloud-devops
          event: fail
          template: basic_fail_1

  scan-frontend:
    <<: *dockerImage
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-test]
      - run:
          name: front-end test
          command: |
            cd frontend
            npm install
            npm install oauth-sign@^0.9.0
            npm audit fix --audit-level=critical
      - slack/notify:
          channel: 03-cloud-devops
          event: fail
          template: basic_fail_1

  scan-backend:
    <<: *dockerImage
    steps:
      - checkout
      - restore_cache:
          keys: [backend-test]
      - run:
          name: back-end test
          command: |
            cd backend
            npm install
            npm install oauth-sign@^0.9.0
            npm audit fix --audit-level=critical
      - slack/notify:
          channel: 03-cloud-devops
          event: fail
          template: basic_fail_1

  deploy-infrastructure:
    working_directory: ~/cdond-c3-projectstarter
    docker:
    - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install tar gzip -y
      - run:
          name: Ensure back-end infrastructure exists
          command: |
            aws cloudformation deploy \
              --template-file .circleci/files/backend.yml \
              --stack-name "udapeople-backend-${CIRCLE_WORKFLOW_ID:0:7}" \
              --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:7}"  \
              --tags project=udapeople
      - run:
          name: Ensure front-end infrastructure exist
          command: |
            aws cloudformation deploy \
              --template-file .circleci/files/frontend.yml \
              --stack-name "udapeople-frontend-${CIRCLE_WORKFLOW_ID:0:7}" \
              --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:7}"  \
              --tags project=udapeople

      - run:
          name: Add back-end ip to ansible inventory; Add the created EC2 instance public IP to the ansible inventory file
          command: |
            aws ec2 describe-instances \
              --filters "Name=tag:Name,Values=backend-${CIRCLE_WORKFLOW_ID:0:7}" \
              --query "Reservations[*].Instances[*].PublicIpAddress" \
              --output text >> .circleci/ansible/inventory.txt \
              --region us-east-1
            cat .circleci/ansible/inventory.txt
            echo CIRCLE_WORKFLOW_ID=${CIRCLE_WORKFLOW_ID:0:7}

      - persist_to_workspace:
          root: ~/cdond-c3-projectstarter
          paths:
            -  .circleci/ansible/inventory.txt 
        # Here's where you will add some code to rollback on failure
      # - destroy-enviroment:
      #     workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}

  configure-infrastructure:
    docker:
      # Docker image here that supports Ansible
      - image: python:3.10-alpine3.16
    steps:
      # Checkout code from git
      - checkout
      # Add ssh keys with fingerprint
      - add_ssh_keys:
          fingerprints:
              - fa:83:4c:5e:0d:90:bd:4f:02:2a:0d:ba:21:7a:28:a2 
      # attach workspace
      - attach_workspace:
            at: ~/cdond-c3-projectstarter
      - run:
          name: Install dependencies
          command: |
            apk add --update --no-cache ansible tar gzip aws-cli openssh
      - run:
          name: Configure server
          command: |
            pwd
            cd .circleci/ansible
            cat inventory.txt 
            ls -al 
            ansible-playbook -i inventory.txt configure-server.yml
          no_output_timeout: 30m
      # Here's where you will add some code to rollback on failure
      # - destroy-enviroment:
      #     workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}

  run-migrations:
    docker:
      - image: circleci/node:12.13.0
      # Docker image here that supports NodeJS
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build]
      - run:
          name: Run migrations
          command: |
            cd backend
            sudo npm install -g npm
            npm run migrations > migrations_dump.txt
            cat migrations_dump.txt
      - run:
          name: Send migration results to kvdb.io
          command: |
              if grep -q "has been executed successfully." ~/cdond-c3-projectstarter/backend/migrations_dump.txt
              then
                 curl https://kvdb.io/9GE4jRtKznmVKRfvdBABBe/migration_${CIRCLE_WORKFLOW_ID:0:7}  -d '1'
              fi
     # Here's where you will add some code to rollback on failure 
     # - destroy-enviroment:
      #     workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}     

  # deploy-frontend:
  #   docker:
  #     - image: python:3.10-alpine3.16
  #   steps:
  #     - checkout
  #     - attach_worksapce:
  #         at: ~/
  #     - run:
  #         name: Install dependencies
  #         command: |
  #           apk add --update --no-cache tar
  #           apk add --update --no-cache gzip
  #           apk add --update --no-cache node.js
  #           apk add --update --no-cache npm
  #           apk add --update --no-cache aws-cli
  #           apk add --update --no-cache curl

  #     - run:
  #         name: Get backend url
  #         command: |
  #           export BACKEND_IP=$(aws ec2 describe-instances \
  #           --query "Reservations[*].[PublicIpAddress]" \
  #           --filters "Name=tag:Name,Values=backend-${CIRCLE_WORKFLOW_ID:0:7}"  \
  #           --output text)
  #           export API_URL="http://${BACKEND_IP}:3030"
  #           echo "${API_URL}"
  #           echo API_URL="http://${BACKEND_IP}:3030"  >> frontend/.env
  #           cat frontend/.env
  #     - run:
  #         name: Deploy frontend objects
  #         command: |
  #           cd frontend
  #           npm install
  #           npm build 
  #           tar -czvf artifact-"${CIRCLE_WORKFLOW_ID:0:7".tar.gz dist 
  #           aws s3 cp dist s3://udapeople-${CIRCLE_WORKFLOW_ID:0:7} --recursive

  #     # Here's where you will add some code to rollback on failure
  #     # - destroy-enviroment:
  #     #     workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}
  #     # - revert-migrations:
  #         # workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}      
                    
  # deploy-backend:
  #   configure-infrastructure:
  #   docker:
  #     # Docker image here that supports Ansible
  #     - image: python:3.10-alpine3.16
  #   steps:
  #     # Checkout code from git
  #     - checkout
  #     # Add ssh keys with fingerprint
  #     - add_ssh_keys:
  #         fingerprints:
  #             - fa:83:4c:5e:0d:90:bd:4f:02:2a:0d:ba:21:7a:28:a2 
  #     # attach workspace
  #     - attach_workspace:
  #           at: ~/
  #     - run:
  #         name: Install dependencies
  #         command: |
  #           apk add --update --no-cache ansible tar gzip nodejs npm curl aws-cli
  #     - run:
  #         name: Deploy backend
  #         command: |
  #           pwd
  #           cd backend

  #           touch .env
  #           echo ENVIROMENT=production > "env"
  #           echo TYPEORM_CONNECTION=postgres >> ".env"
  #           echo TYPEORM_ENTITIES:=./src/modules/domain/**/*.entity.ts >> ".env"
  #           echo TYPEORM_MIGRATIONS:=./src/migrations/*.ts >>".env"
  #           echo TYPEORM_MIGRATIONS_DIR=./src/migrations >>".env"
  #           echo NODE_ENV=production >> ".env"             
  #           echo TYPEORM_HOST=$TYPEORM_HOST >> ".env" 
  #           echo TYPEORM_PORT=$TYPEORM_PORT >> ".env" 
  #           echo TYPEORM_USERNAME=$TYPEORM_USERNAME >> ".env" 
  #           echo TYPEORM_PASSWORD=$TYPEORM_PASSWORD >> ".env" 
  #           echo TYPEORM_DATABASE=$TYPEORM_DATABASE >> ".env"

  #           pwd
  #           ls -al
  #           npm install
  #           npm run build
  #           cd ..
  #           pwd
  #           ls -al
  #           tar -C backend -czvf artifact.tar.gz .

  #           cd .circleci/ansible

  #           echo "contents of the inventory.txt file is -------"
  #           cat inventory.txt
  #           ansible-playbook -i inventory.txt deploy-backend.yml

  #     # Here's where you will add some code to rolln on failure  
  #     # - destroy-enviroment:
  #     #     workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}
  #     # - revert-migrations:
  #         # workflow_id: ${CIRCLE_WORKFLOW_ID:0:7} 

  # smoke-test:
  #   docker:
  #     - image: python:3.10-alpine3.16
  #   steps:
  #     - checkout
  #     - run:
  #         name: Install dependencies
  #         command: |
  #           apk add --update --no-cache tar gzip node.js npm curl aws-cli
  #     - run:
  #         name: Get backend url and smoke test
  #         command: |
  #           export BACKEND_IP=$(aws ec2 describe-instances \
  #           --query "Reservations[*].[PublicIpAddress]" \
  #           --filters "Name=tag:Name,Values=backend-${CIRCLE_WORKFLOW_ID:0:7}"  \
  #           --output text)
  #           echo ${BACKEND_IP}

  #           export BACKEND_IP=$(echo $BACKEND_IP | grep -o '[^ ]*$')
             
  #            echo $BACKEND
  #            export API_URL="http://${BACKEND_IP}:3030"
  #            echo "API_URL=${API_URL}"

  #           echo "Sleeping for 1 minute"
  #           sleep 60

  #           if curl -v "${API_URL}/api/status" | grep "ok"
  #           then
  #             return 0
  #           else
  #             return 1
  #           fi
  
  #     - run:
  #         name: Frontend smoke test.
  #         command: |
  #           URL="http://udapeople-${CIRCLE_WORKFLOW_ID:0:7}.s3-website-us-east-1.amazonaws.com/#/employees"
  #             echo ${URL}

  #             if curl -s ${URL} | grep "Welcome"
  #             then
  #               return 0
  #             else
  #               return 1
  #             fi
  #   # Here's where you will add some code to rollback on failure 
  #       - destroy-enviroment:
  #     #     workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}
  #     # - revert-migrations:
  #         # workflow_id: ${CIRCLE_WORKFLOW_ID:0:7} 

  # cloudfront-update:
  #   docker:
  #     # Docker image here that supports AWS CLI
  #   steps:
  #     # Checkout code from git
  #     - run:
  #         name: Install dependencies
  #         command: |
  #           # your code here
  #     - run:
  #         name: Update cloudfront distribution
  #         command: |
  #           # your code here
  #     # Here's where you will add some code to rollback on failure  

# cleanup:
#     docker:
#       # Docker image here
#     steps:
#       # Checkout code from git
#       - run:
#           name: Get old stack workflow id
#           command: |
#             # your code here
#             export OldWorkflowID="the id here"
#             export STACKS=[] #put the list of stacks here
#       - run:
#           name: Remove old stacks and files
#           command: |
#             if [[ "${STACKS[@]}" =~ "${OldWorkflowID}" ]]
#             then
#               # your code here
#             fi



workflows:
  default:
    jobs:
      - build-frontend
      - build-backend
      - test-frontend:
          requires: [build-frontend]
      - test-backend:
          requires: [build-backend]
      - scan-backend:
          requires: [build-backend]
      - scan-frontend:
          requires: [build-frontend]
      - deploy-infrastructure:
          requires: [test-frontend, test-backend, scan-frontend, scan-backend]
          filters:
            branches:
              only: [busolaWork]
      - configure-infrastructure:
          requires: [deploy-infrastructure]
      - run-migrations:
          requires: [configure-infrastructure]
